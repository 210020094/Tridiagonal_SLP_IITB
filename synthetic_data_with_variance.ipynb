{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# also import for Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results_new2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DataLabel', 'TP', 'TE1', 'TE2', 'TE3', 'TE4', 'Program Number',\n",
      "       'Batch Status', 'Min_ster_Temp', 'Max_ster_Temp', 'Overall Avg TE1',\n",
      "       'Overall Avg TE2', 'Overall Avg TE3', 'Overall Avg TE4',\n",
      "       'Overall Avg TP', 'Overall Var TE1', 'Overall Var TE2',\n",
      "       'Overall Var TE3', 'Overall Var TE4', 'Overall Var TP', 'Time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print all columns in dataframe\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new dataframe with only the columns we want which are  'Overall Var TE1', 'Overall Var TE2','Overall Var TE3', 'Overall Var TE4', 'Overall Var TP', 'Batch Status', 'Min_ster_Temp', 'Max_ster_Temp'\n",
    "\n",
    "\n",
    "# drop the Time column from dataframe\n",
    "df = df.drop('Time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataLabel</th>\n",
       "      <th>TP</th>\n",
       "      <th>TE1</th>\n",
       "      <th>TE2</th>\n",
       "      <th>TE3</th>\n",
       "      <th>TE4</th>\n",
       "      <th>Program Number</th>\n",
       "      <th>Batch Status</th>\n",
       "      <th>Min_ster_Temp</th>\n",
       "      <th>Max_ster_Temp</th>\n",
       "      <th>Overall Avg TE1</th>\n",
       "      <th>Overall Avg TE2</th>\n",
       "      <th>Overall Avg TE3</th>\n",
       "      <th>Overall Avg TE4</th>\n",
       "      <th>Overall Avg TP</th>\n",
       "      <th>Overall Var TE1</th>\n",
       "      <th>Overall Var TE2</th>\n",
       "      <th>Overall Var TE3</th>\n",
       "      <th>Overall Var TE4</th>\n",
       "      <th>Overall Var TP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.110000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>122.100000</td>\n",
       "      <td>122.200000</td>\n",
       "      <td>122.100000</td>\n",
       "      <td>8</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>122.1</td>\n",
       "      <td>122.2</td>\n",
       "      <td>47.120690</td>\n",
       "      <td>114.396238</td>\n",
       "      <td>115.152978</td>\n",
       "      <td>114.968966</td>\n",
       "      <td>1.547931</td>\n",
       "      <td>2803.869759</td>\n",
       "      <td>131.966338</td>\n",
       "      <td>112.167656</td>\n",
       "      <td>115.738436</td>\n",
       "      <td>0.657171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.109180</td>\n",
       "      <td>121.744262</td>\n",
       "      <td>121.963115</td>\n",
       "      <td>122.161475</td>\n",
       "      <td>122.013934</td>\n",
       "      <td>8</td>\n",
       "      <td>OK</td>\n",
       "      <td>121.2</td>\n",
       "      <td>122.2</td>\n",
       "      <td>92.999427</td>\n",
       "      <td>112.804585</td>\n",
       "      <td>113.555301</td>\n",
       "      <td>113.648711</td>\n",
       "      <td>1.100487</td>\n",
       "      <td>874.492528</td>\n",
       "      <td>127.465898</td>\n",
       "      <td>114.342824</td>\n",
       "      <td>109.503023</td>\n",
       "      <td>0.728475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.108934</td>\n",
       "      <td>121.779508</td>\n",
       "      <td>122.040164</td>\n",
       "      <td>122.269672</td>\n",
       "      <td>122.140164</td>\n",
       "      <td>3</td>\n",
       "      <td>OK</td>\n",
       "      <td>121.2</td>\n",
       "      <td>122.4</td>\n",
       "      <td>90.738629</td>\n",
       "      <td>113.893458</td>\n",
       "      <td>114.797819</td>\n",
       "      <td>114.575701</td>\n",
       "      <td>1.074486</td>\n",
       "      <td>925.593441</td>\n",
       "      <td>86.884676</td>\n",
       "      <td>77.099151</td>\n",
       "      <td>81.663595</td>\n",
       "      <td>0.849215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.109024</td>\n",
       "      <td>121.760163</td>\n",
       "      <td>121.968293</td>\n",
       "      <td>122.203252</td>\n",
       "      <td>122.082927</td>\n",
       "      <td>11</td>\n",
       "      <td>OK</td>\n",
       "      <td>121.2</td>\n",
       "      <td>122.3</td>\n",
       "      <td>88.138739</td>\n",
       "      <td>113.450450</td>\n",
       "      <td>114.356156</td>\n",
       "      <td>114.064565</td>\n",
       "      <td>1.073874</td>\n",
       "      <td>967.878284</td>\n",
       "      <td>89.466001</td>\n",
       "      <td>81.164036</td>\n",
       "      <td>86.763680</td>\n",
       "      <td>0.824727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.109754</td>\n",
       "      <td>121.595902</td>\n",
       "      <td>121.831148</td>\n",
       "      <td>122.027869</td>\n",
       "      <td>121.883607</td>\n",
       "      <td>10</td>\n",
       "      <td>OK</td>\n",
       "      <td>121.2</td>\n",
       "      <td>122.1</td>\n",
       "      <td>92.804469</td>\n",
       "      <td>102.759497</td>\n",
       "      <td>102.860056</td>\n",
       "      <td>103.077933</td>\n",
       "      <td>1.959721</td>\n",
       "      <td>879.638523</td>\n",
       "      <td>473.956702</td>\n",
       "      <td>492.689689</td>\n",
       "      <td>450.135114</td>\n",
       "      <td>0.143143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DataLabel        TP         TE1         TE2         TE3         TE4  \\\n",
       "0          1  2.110000    0.000000  122.100000  122.200000  122.100000   \n",
       "1          2  2.109180  121.744262  121.963115  122.161475  122.013934   \n",
       "2          3  2.108934  121.779508  122.040164  122.269672  122.140164   \n",
       "3          4  2.109024  121.760163  121.968293  122.203252  122.082927   \n",
       "4          5  2.109754  121.595902  121.831148  122.027869  121.883607   \n",
       "\n",
       "   Program Number Batch Status  Min_ster_Temp  Max_ster_Temp  Overall Avg TE1  \\\n",
       "0               8       FAILED          122.1          122.2        47.120690   \n",
       "1               8           OK          121.2          122.2        92.999427   \n",
       "2               3           OK          121.2          122.4        90.738629   \n",
       "3              11           OK          121.2          122.3        88.138739   \n",
       "4              10           OK          121.2          122.1        92.804469   \n",
       "\n",
       "   Overall Avg TE2  Overall Avg TE3  Overall Avg TE4  Overall Avg TP  \\\n",
       "0       114.396238       115.152978       114.968966        1.547931   \n",
       "1       112.804585       113.555301       113.648711        1.100487   \n",
       "2       113.893458       114.797819       114.575701        1.074486   \n",
       "3       113.450450       114.356156       114.064565        1.073874   \n",
       "4       102.759497       102.860056       103.077933        1.959721   \n",
       "\n",
       "   Overall Var TE1  Overall Var TE2  Overall Var TE3  Overall Var TE4  \\\n",
       "0      2803.869759       131.966338       112.167656       115.738436   \n",
       "1       874.492528       127.465898       114.342824       109.503023   \n",
       "2       925.593441        86.884676        77.099151        81.663595   \n",
       "3       967.878284        89.466001        81.164036        86.763680   \n",
       "4       879.638523       473.956702       492.689689       450.135114   \n",
       "\n",
       "   Overall Var TP  \n",
       "0        0.657171  \n",
       "1        0.728475  \n",
       "2        0.849215  \n",
       "3        0.824727  \n",
       "4        0.143143  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# do label encoding, apply 1 for OK and apply 0 for all others in Batch status, and later delete the batch status column\n",
    "df['Batch Status_encoded'] = df['Batch Status'].apply(lambda x: 1 if x == 'OK' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace batch status with batch status encoded\n",
    "df = df.drop(columns=['Batch Status'])\n",
    "df = df.rename(columns={'Batch Status_encoded': 'Batch Status'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_vectors(df):\n",
    "    vectors = []\n",
    "    for i in range(len(df) - 20):\n",
    "        vector = df.iloc[i:i+20].values.flatten()\n",
    "        vectors.append(vector)\n",
    "    return vectors\n",
    "\n",
    "vectors = df_to_vectors(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1840, 400)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vectors = np.array(vectors)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1840,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output of each batch status\n",
    "batch_statuses = df['Batch Status'].values[21:]\n",
    "# append the last row as a 1 \n",
    "batch_statuses = np.append(batch_statuses, 1)\n",
    "\n",
    "batch_statuses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1507\n",
       "0     353\n",
       "Name: Batch Status, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check batch statuses value counts\n",
    "df['Batch Status'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to feature vectors and target variable\n",
    "X = vectors\n",
    "y = batch_statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into failed and passed batches\n",
    "failed_indices = np.where(y == 0)[0]\n",
    "passed_indices = np.where(y == 1)[0]\n",
    "# Split the failed batches into train and test sets\n",
    "failed_indices_train, failed_indices_test = train_test_split(failed_indices, test_size=0.2)\n",
    "# do similar split for passed indices\n",
    "passed_indices_train, passed_indices_test = train_test_split(passed_indices, test_size=0.2)\n",
    "# combine train and test indices separately, including passed and failed\n",
    "train_indices = np.concatenate((failed_indices_train, passed_indices_train))\n",
    "test_indices = np.concatenate((failed_indices_test, passed_indices_test))\n",
    "\n",
    "\n",
    "# # Combine the indices of train and test sets with passed indices\n",
    "# train_indices = np.concatenate((failed_indices_train, passed_indices))\n",
    "# test_indices = np.concatenate((failed_indices_test, passed_indices[:4*len(failed_indices_test)]))\n",
    "\n",
    "# Shuffle the indices to ensure randomness\n",
    "np.random.shuffle(train_indices)\n",
    "np.random.shuffle(test_indices)\n",
    "\n",
    "# Use the indices to get the corresponding data\n",
    "X_train, y_train = X[train_indices], y[train_indices]\n",
    "X_test, y_test = X[test_indices], y[test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train value counts\n",
      "1    1195\n",
      "0     276\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print y_train value counts\n",
    "print('y_train value counts')\n",
    "print(pd.Series(y_train).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify minority class label\n",
    "minority_class_label = 0  # Assuming failed batches are labeled as 0\n",
    "\n",
    "# Find indices of minority class samples in the training set\n",
    "minority_indices_train = np.where(y_train == minority_class_label)[0]\n",
    "\n",
    "# Extract minority class samples in the training set\n",
    "X_minority_train = X_train[minority_indices_train]\n",
    "y_minority_train = y_train[minority_indices_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to generate synthetic samples for minority class\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train data shape: (1471, 400)\n",
      "Resampled train data shape: (2390, 400)\n",
      "Original class distribution:\n",
      "1    1195\n",
      "0     276\n",
      "dtype: int64\n",
      "Resampled class distribution:\n",
      "1    1195\n",
      "0    1195\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of the original and resampled train data\n",
    "print('Original train data shape:', X_train.shape)\n",
    "print('Resampled train data shape:', X_train_resampled.shape)\n",
    "\n",
    "# Display the number of samples in each class before and after resampling\n",
    "print('Original class distribution:')\n",
    "print( pd.Series(y_train).value_counts())\n",
    "print('Resampled class distribution:')\n",
    "print(pd.Series(y_train_resampled).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_resampled: (2390, 400)\n",
      "Shape of y_train_resampled: (2390,)\n",
      "Shape of X_train: (1471, 400)\n",
      "Shape of y_train: (1471,)\n",
      "Shape of X_test: (369, 400)\n",
      "Shape of y_test: (369,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the shape of the resampled training data\n",
    "print(\"Shape of X_train_resampled:\", X_train_resampled.shape)\n",
    "print(\"Shape of y_train_resampled:\", y_train_resampled.shape)\n",
    "\n",
    "# Print the shape of all datasets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.7046070460704607\n",
      "Accuracy on resampled training set: 1.0\n",
      "Mean Squared Error on test set: 0.2953929539295393\n",
      "Classification Report on test set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.33      0.30        70\n",
      "           1       0.83      0.79      0.81       299\n",
      "\n",
      "    accuracy                           0.70       369\n",
      "   macro avg       0.55      0.56      0.55       369\n",
      "weighted avg       0.73      0.70      0.72       369\n",
      "\n",
      "Confusion Matrix on test set:\n",
      " [[ 23  47]\n",
      " [ 62 237]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize and train Decision Tree classifier using resampled training data\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_dt = clf.predict(X_test)\n",
    "# prediction on train set\n",
    "y_pred_train = clf.predict(X_train_resampled)\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "accuracy_test = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Accuracy on test set:\", accuracy_test)\n",
    "\n",
    "# Calculate accuracy on resampled training set\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_pred_train)\n",
    "print(\"Accuracy on resampled training set:\", accuracy_train)\n",
    "\n",
    "# Calculate mean squared error on test set\n",
    "mse = mean_squared_error(y_test, y_pred_dt)\n",
    "print(\"Mean Squared Error on test set:\", mse)\n",
    "\n",
    "# Generate classification report on test set\n",
    "class_report = classification_report(y_test, y_pred_dt)\n",
    "print(\"Classification Report on test set:\\n\", class_report)\n",
    "\n",
    "# Generate confusion matrix on test set\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"Confusion Matrix on test set:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set (Random Forest): 0.7994579945799458\n",
      "Accuracy on resampled training set (Random Forest): 1.0\n",
      "Mean Squared Error on test set (Random Forest): 0.2005420054200542\n",
      "Classification Report on test set (Random Forest):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.21      0.29        70\n",
      "           1       0.84      0.94      0.88       299\n",
      "\n",
      "    accuracy                           0.80       369\n",
      "   macro avg       0.64      0.58      0.59       369\n",
      "weighted avg       0.76      0.80      0.77       369\n",
      "\n",
      "Confusion Matrix on test set (Random Forest):\n",
      " [[ 15  55]\n",
      " [ 19 280]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize and train Random Forest classifier using resampled training data\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "y_pred_train_rf = rf_clf.predict(X_train_resampled)\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "accuracy_test_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy on test set (Random Forest):\", accuracy_test_rf)\n",
    "\n",
    "# Calculate accuracy on resampled training set\n",
    "accuracy_train_rf = accuracy_score(y_train_resampled, y_pred_train_rf)\n",
    "print(\"Accuracy on resampled training set (Random Forest):\", accuracy_train_rf)\n",
    "\n",
    "# Calculate mean squared error on test set\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(\"Mean Squared Error on test set (Random Forest):\", mse_rf)\n",
    "\n",
    "# Generate classification report on test set\n",
    "class_report_rf = classification_report(y_test, y_pred_rf)\n",
    "print(\"Classification Report on test set (Random Forest):\\n\", class_report_rf)\n",
    "\n",
    "# Generate confusion matrix on test set\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Confusion Matrix on test set (Random Forest):\\n\", conf_matrix_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set (Logistic Regression): 0.6368563685636857\n",
      "Accuracy on resampled training set (Logistic Regression): 0.7753138075313808\n",
      "Mean Squared Error on test set (Logistic Regression): 0.36314363143631434\n",
      "Classification Report on test set (Logistic Regression):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.43      0.31        70\n",
      "           1       0.84      0.69      0.75       299\n",
      "\n",
      "    accuracy                           0.64       369\n",
      "   macro avg       0.54      0.56      0.53       369\n",
      "weighted avg       0.72      0.64      0.67       369\n",
      "\n",
      "Confusion Matrix on test set (Logistic Regression):\n",
      " [[ 30  40]\n",
      " [ 94 205]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91751\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize and train Logistic Regression classifier using resampled training data\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "y_pred_train_log_reg = log_reg.predict(X_train_resampled)\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "accuracy_test_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "print(\"Accuracy on test set (Logistic Regression):\", accuracy_test_log_reg)\n",
    "\n",
    "# Calculate accuracy on resampled training set\n",
    "accuracy_train_log_reg = accuracy_score(y_train_resampled, y_pred_train_log_reg)\n",
    "print(\"Accuracy on resampled training set (Logistic Regression):\", accuracy_train_log_reg)\n",
    "\n",
    "# Calculate mean squared error on test set\n",
    "mse_log_reg = mean_squared_error(y_test, y_pred_log_reg)\n",
    "print(\"Mean Squared Error on test set (Logistic Regression):\", mse_log_reg)\n",
    "\n",
    "# Generate classification report on test set\n",
    "class_report_log_reg = classification_report(y_test, y_pred_log_reg)\n",
    "print(\"Classification Report on test set (Logistic Regression):\\n\", class_report_log_reg)\n",
    "\n",
    "# Generate confusion matrix on test set\n",
    "conf_matrix_log_reg = confusion_matrix(y_test, y_pred_log_reg)\n",
    "print(\"Confusion Matrix on test set (Logistic Regression):\\n\", conf_matrix_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
